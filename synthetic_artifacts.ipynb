{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook creates a synthetic experiment to demonstrate annotation artifacts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load up the requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn import linear_model\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set dataset sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntrain = 30000\n",
    "ntest = 300\n",
    "nfeats = 300\n",
    "nclasses = 3\n",
    "\n",
    "assert nfeats % nclasses == 0 # We want to make sure we have three (orthonormal) clusters. Not strictly required.\n",
    "assert ntrain % nclasses == 0 # Ensures balanced train data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(pred, ref):\n",
    "    correct = sum((pred == ref).astype('int'))\n",
    "    return correct/len(ref)\n",
    "\n",
    "\n",
    "def shuffle_dataset(x, y):\n",
    "    floaty = np.expand_dims(y, axis=1).astype('float')\n",
    "    xy = np.concatenate((x, floaty), axis=1)\n",
    "    np.random.shuffle(xy)\n",
    "    x = xy.T[:-1].T\n",
    "    y = xy.T[-1].T.astype('int')\n",
    "    return x, y\n",
    "\n",
    "\n",
    "def create_ex_uniform_random(shuffle=True):\n",
    "    \"\"\"\n",
    "    Sample from uniform random distribution to create train and test sets.\n",
    "    \"\"\"\n",
    "    X = np.random.rand(ntrain, nfeats)\n",
    "    Y = np.random.randint(0, nclasses, ntrain)\n",
    "    xtest = np.random.rand(ntest, nfeats)\n",
    "    ytest = np.random.randint(0, nclasses, ntest)\n",
    "    \n",
    "    if shuffle:\n",
    "        X, Y = shuffle_dataset(X, Y)\n",
    "    \n",
    "    return X, Y, xtest, ytest\n",
    "\n",
    "\n",
    "def create_ex_multivariate_normal(nfeats, ntrain, ntest, shuffle=True):\n",
    "    \"\"\"\n",
    "    Sample from 3 different multivariate Gaussian distributions to create train and test sets.\n",
    "    \"\"\"\n",
    "    covariance = np.diag(np.full(nfeats, 1))  # Use the same for all 3 clusters.\n",
    "    mean = np.full(nfeats, 0)\n",
    "    mean[nfeats // nclasses] = 1  # To ensure orthonormality of clusters.\n",
    "    \n",
    "    X = np.random.multivariate_normal(mean, covariance, ntrain//nclasses)\n",
    "    Y = np.full(ntrain//nclasses, 0)\n",
    "    xtest = np.random.multivariate_normal(mean, covariance, ntest//nclasses) \n",
    "    ytest = np.full(ntest//nclasses, 0)\n",
    "    \n",
    "    for i in range(1, nclasses):\n",
    "        mean = np.full(nfeats, 0)\n",
    "        mean[(i+1) * nfeats // nclasses - 1] = 1\n",
    "    \n",
    "        ex = np.random.multivariate_normal(mean, covariance, ntrain//nclasses)\n",
    "        X = np.concatenate((X, ex), axis=0)\n",
    "        \n",
    "        label = np.full(ntrain//nclasses, i)\n",
    "        Y = np.concatenate((Y, label), axis=0)\n",
    "        \n",
    "        test_ex = np.random.multivariate_normal(mean, covariance, ntest//nclasses)\n",
    "        xtest = np.concatenate((xtest, test_ex), axis=0)\n",
    "        \n",
    "        test_y = np.full(ntest//nclasses, i)\n",
    "        ytest = np.concatenate((ytest, test_y), axis=0)\n",
    "        \n",
    "    # Shuffle the train.\n",
    "    if shuffle:\n",
    "        X, Y = shuffle_dataset(X, Y)\n",
    "    return X, Y, xtest, ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [],
   "source": [
    "def introduce_cheat_feature(x, y, randomize):\n",
    "    if randomize:\n",
    "        random_feats = int(len(x) * randomize)//3\n",
    "        mask0 = np.full(random_feats, 0)\n",
    "        mask1 = np.full(random_feats, 1)\n",
    "        mask2 = np.full(random_feats, 2)\n",
    "\n",
    "        mask = np.concatenate((mask0, mask1, mask2))\n",
    "        np.random.shuffle(mask)\n",
    "        \n",
    "        masked_y = np.copy(y)\n",
    "        masked_y[:(len(mask))] = mask\n",
    "    else:\n",
    "        masked_y = y\n",
    "\n",
    "    ycheatfeat = np.expand_dims(masked_y.astype('float'), axis=1)\n",
    "    xcheatfeat = np.concatenate((x, ycheatfeat), axis=1)\n",
    "    return xcheatfeat\n",
    "\n",
    "# introduce_cheat_feature(np.random.rand(18, 3), np.random.randint(0, 3, 18), 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create train and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: 30000, Y:30000, x-test:300, y-test:300\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Num features', 300)"
      ]
     },
     "execution_count": 503,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X, Y, xtest, ytest = create_ex_uniform_random()\n",
    "\n",
    "xtrain, ytrain, xtest, ytest = create_ex_multivariate_normal(nfeats, ntrain, ntest, shuffle=False)\n",
    "print(f\"X: {len(xtrain)}, Y:{len(ytrain)}, x-test:{len(xtest)}, y-test:{len(ytest)}\")\n",
    "\"Num features\", nfeats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline\n",
    "#### Train and test a linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BASELINE test acc: 0.6033 train acc: 0.6066'"
      ]
     },
     "execution_count": 508,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if os.path.exists('x/baseline.joblib'):\n",
    "    clf = load('baseline.joblib')\n",
    "else:\n",
    "    clf = linear_model.SGDClassifier(max_iter=1000, tol=1e-3)\n",
    "    clf.fit(xtrain, ytrain)\n",
    "    dump(clf, 'baseline.joblib') \n",
    "\n",
    "ypred = clf.predict(xtest)\n",
    "f\"BASELINE test acc: {accuracy(ypred, ytest):.4} train acc: {accuracy(clf.predict(xtrain), ytrain):.4}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cheating\n",
    "#### Train a cheater model, which uses labels as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CHEATER train acc: 0.9908'"
      ]
     },
     "execution_count": 509,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cheat_train = introduce_cheat_feature(xtrain, ytrain, randomize=0.)\n",
    "\n",
    "if os.path.exists('x/cheater.joblib'):\n",
    "    cheater = load('cheater.joblib')\n",
    "else:\n",
    "    cheater = linear_model.SGDClassifier(max_iter=1000, tol=1e-3)\n",
    "    cheater.fit(cheat_train, ytrain)\n",
    "    dump(cheater, 'cheater.joblib') \n",
    "    \n",
    "f\"CHEATER train acc: {accuracy(cheater.predict(cheat_train), ytrain):.4}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### At various levels of randomization of the cheat feature, see test performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHEATER randomization: test acc\n",
      "                  0.0: 0.9967\n",
      "                  0.2: 0.87\n",
      "                  0.4: 0.7467\n",
      "                  0.6: 0.58\n",
      "                  0.8: 0.4567\n",
      "                  0.9: 0.4633\n",
      "                  1.0: 0.3567\n"
     ]
    }
   ],
   "source": [
    "print(\"CHEATER randomization: test acc\")\n",
    "for r in [0., 0.2, 0.4, 0.6, 0.8, 0.9, 1.]:\n",
    "    cheat_test = introduce_cheat_feature(xtest, ytest, randomize=r)\n",
    "\n",
    "    cheat_prediction = cheater.predict(cheat_test)\n",
    "    print(f\"{r:21}: {accuracy(cheat_prediction, ytest):.4}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cheating some of the time\n",
    "#### This model cheats some of the time; 50% of the time, cheat features are identical to the true class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PARTIAL-CHEATER train acc: 0.7264'"
      ]
     },
     "execution_count": 513,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partial_cheat_train = introduce_cheat_feature(X, Y, randomize=.5)\n",
    "\n",
    "if os.path.exists('x/partial_cheater.joblib'):\n",
    "    partial_cheater = load('partial_cheater.joblib')\n",
    "else:\n",
    "    partial_cheater = linear_model.SGDClassifier(max_iter=1000, tol=1e-3)\n",
    "    partial_cheater.fit(partial_cheat_train, Y)\n",
    "    dump(partial_cheater, 'partial_cheater.joblib') \n",
    "f\"PARTIAL-CHEATER train acc: {accuracy(partial_cheater.predict(partial_cheat_train), ytrain):.4}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### At various levels of randomization of the cheat feature, see test performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PARTIAL-CHEATER randomization: test acc\n",
      "                          0.0: 0.8\n",
      "                          0.2: 0.7733\n",
      "                          0.4: 0.75\n",
      "                          0.6: 0.7333\n",
      "                          0.8: 0.6333\n",
      "                          0.9: 0.56\n",
      "                          1.0: 0.5033\n"
     ]
    }
   ],
   "source": [
    "print(\"PARTIAL-CHEATER randomization: test acc\")\n",
    "for r in [0., 0.2, 0.4, 0.6, 0.8, 0.9, 1.]:\n",
    "    partial_cheat_test = introduce_cheat_feature(xtest, ytest, randomize=r)\n",
    "\n",
    "    partial_cheat_pred = partial_cheater.predict(partial_cheat_test)\n",
    "    print(f\"{r:29}: {accuracy(partial_cheat_pred, ytest):.4}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling cheat features (artifacts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [],
   "source": [
    "def introduce_cheat_features_from_gaussian(probs, ntotal, mean, covariance=0.1):\n",
    "    assert len(probs) == nclasses\n",
    "\n",
    "    n = ntotal//nclasses  # number of examples per class.\n",
    "    features = np.array([])\n",
    "    for p in probs:\n",
    "        cheat_feats = np.random.normal(mean, covariance, int(p*n))\n",
    "        rest = n - len(cheat_feats)\n",
    "        cheat_feats = np.concatenate((cheat_feats, np.random.rand(rest)), axis=0)\n",
    "        np.random.shuffle(cheat_feats)\n",
    "        features = np.concatenate((features, cheat_feats), axis=0)\n",
    "    assert len(features) == ntotal\n",
    "    return np.expand_dims(features, axis=1)\n",
    "\n",
    "# introduce_cheat_features_from_gaussian(probs=[0.5, 0.25, 0.25], ntotal=18, mean=500.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create training features with cheating, based on a multinomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PARTIAL-CHEATER train acc: 0.8427333333333333'"
      ]
     },
     "execution_count": 517,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob = [0.1, 0.1, 0.1]  # base probability for \n",
    "cheater_multin_feats_train = np.copy(xtrain)\n",
    "\n",
    "for i, mean in enumerate([10, 100, -100]):\n",
    "    prob_class = np.copy(prob)\n",
    "    prob_class[i] = 0.8\n",
    "    cheat_feats = introduce_cheat_features_from_gaussian(probs=prob_class, ntotal=ntrain, mean=mean)\n",
    "    cheater_multin_feats_train = np.concatenate((cheater_multin_feats_train, cheat_feats), axis=1)\n",
    "\n",
    "\n",
    "cheater_dist = linear_model.SGDClassifier(max_iter=1000, tol=1e-3)\n",
    "cheater_dist.fit(cheater_multin_feats_train, Y)\n",
    "\n",
    "f\"MULTINOMIAL-CHEATER train acc: {accuracy(cheater_dist.predict(cheater_multin_feats_train), ytrain)}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Different probs for cheater distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MULTINOMIAL-CHEATER randomization: test acc\n",
      "                              0.0: 0.5\n",
      "                              0.2: 0.61\n",
      "                              0.4: 0.6733\n",
      "                              0.6: 0.7567\n",
      "                              0.8: 0.8433\n",
      "                              0.9: 0.88\n",
      "                              1.0: 0.92\n"
     ]
    }
   ],
   "source": [
    "print(\"MULTINOMIAL-CHEATER randomization: test acc\")\n",
    "for p in [0., 0.2, 0.4, 0.6, 0.8, 0.9, 1.]:\n",
    "    cheater_feats_test = np.copy(xtest)\n",
    "    for i, mean in enumerate([10, 100, -100]):\n",
    "        prob_class = np.copy(prob)\n",
    "        prob_class[i] = p\n",
    "        class_feats_test = introduce_cheat_features_from_gaussian(probs=prob_class, ntotal=ntest, mean=mean)\n",
    "        cheater_feats_test = np.concatenate((cheater_feats_test, class_feats_test), axis=1)\n",
    "    \n",
    "    print(f\"{p:33}: {accuracy(cheater_dist.predict(cheater_feats_test), ytest):.4}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
